# Feature Interactions: An Agent-Based Model of Open-Ended Evolution

Dissertation research project — Portland State University, Systems Science PhD Program

## Overview

This project implements a large-scale agent-based model (ABM) to study **open-ended evolution (OEE)**: the capacity of evolutionary systems to generate novelty and complexity indefinitely, rather than converging to fixed solutions. The model focuses specifically on **role-system dynamics** — how functional specializations (roles) emerge, persist, and interact in evolving populations over extended time periods.

The core research question: under what conditions do ecological, economic, and social systems exhibit genuine *development* — the emergence of novel types of agents and relations — rather than mere *growth* (increases in population without increases in variety)?

A manuscript based on this research has been submitted to *Artificial Life*, the dedicated peer-reviewed journal for the field.

## Model Architecture

### Key Concepts

- **Features** — heritable characteristics agents possess. Features can be agent-level (traits agents carry) or environmental (properties of grid sites). Features are named automatically and can emerge through mutation.
- **Traits** — the specific values a feature can take. Traits also evolve; new trait values can emerge through mutation.
- **Interactions** — directed relationships between features with associated payoff matrices. When an agent's feature interacts with another agent's (or a site's) feature, both parties receive utility payoffs determined by their respective trait values.
- **Roles** — defined by an agent's feature set (the *frozenset* of features an agent possesses). Agents with the same set of features occupy the same role regardless of their trait values. Roles emerge dynamically from agent evolution.
- **Rolesets** — the set of roles present at a given site and timestep. The roleset evaluation algorithm assesses which roles are viable, occupied, adjacent, and occupiable given current environmental and population conditions.

### Core Components

**`model/agents.py`** — Defines `Agent` and `Site` classes. Agents interact, reproduce with mutation, move, and die based on utility dynamics. Each agent maintains a utility value updated through environmental and agent-agent interactions. Sites track population dynamics, environmental trait values, and interaction statistics.

**`model/features.py`** — Defines `Feature`, `Trait`, and `Interaction` classes. Manages payoff matrices for all feature-trait combinations. Features and traits can be created dynamically during simulation runs.

**`model/world.py`** — The `World` class (Mesa `Model` subclass) manages the simulation grid, agent schedule, feature interaction network, and per-step data collection. Supports a **shadow model** architecture: a parallel neutral-drift world runs alongside each primary world, providing a baseline for measuring selection effects.

**`model/grid.py`** — Custom `ListDict` grid implementation that significantly outperforms Mesa's default grid for high-frequency agent birth/death operations. Standard Mesa grids require traversing the full agent list to remove dead agents; `ListDict` maintains a dictionary-indexed structure enabling O(1) removal, which is critical when simulations involve hundreds of thousands of agents across tens of thousands of timesteps.

**`model/run.py`** — The `Controller` class manages the complete research pipeline: experiment configuration, database initialization, parameter sweep generation, parallel process coordination, and output organization. The `main()` function accepts a JSON configuration file and automatically creates timestamped experiment directories, copies configuration files for reproducibility, and dispatches either sequential or multiprocessing execution based on available CPU resources (detects `SLURM_CPUS_PER_TASK` for HPC cluster execution).

**`model/database.py`** — SQLite-based data persistence layer. The `Manager` class handles table creation, row writes, and database organization. Query functions return Pandas DataFrames for analysis. Databases generated by typical experiment runs range from 2–40GB depending on simulation scale and collection intervals.

**`model/rolesets.py`** — Post-hoc roleset analysis from database output. The `FeatureUtilityCalculator` computes expected utility for each feature-trait combination at each site and timestep. The `RoleAnalyzer` uses these utilities to evaluate which roles are viable (can sustain positive utility), occupied, adjacent to occupied roles, and occupiable. Includes caching at multiple levels to manage the computational cost of analyzing large databases.

**`model/analysis.py`** — Visualization classes built on Matplotlib and Seaborn: `PopulationPlot` (area/line plots of phenotype and role distributions over time), `HeatmapPlot` (log-scale role population heatmaps), `ModelVarsPlot` (time-series plots of population, utility, phenotype/role counts, interaction rates), and `PayoffPlot` (payoff distribution visualizations).

## Experiment Configuration

Experiments are defined via JSON configuration files:

```json
{
  "title": "experiment_name",
  "output_path": "/path/to/output",
  "db_interval": 5,
  "data_interval": 10,
  "num_networks": 3,
  "num_iterations": 5,
  "max_steps": 50000,
  "network_params": {
    "init_env_features": 3,
    "init_agent_features": 3,
    "max_feature_interactions": 6,
    "trait_payoff_mod": 0.5,
    "anchor_bias": 0.5,
    "payoff_bias": 0.5
  },
  "world_params": {
    "init_agents": 500,
    "grid_size": 10,
    "trait_mutate_chance": 0.01,
    "feature_mutate_chance": 0.005,
    "feature_create_chance": 0.3,
    "feature_gain_chance": 0.5,
    "base_agent_utils": 1.0,
    "base_env_utils": 1.0,
    "total_pop_limit": 300000,
    "pop_cost_exp": 2.0,
    "feature_cost_exp": 2.0,
    "repr_multi": 2,
    "mortality": 0.01,
    "move_chance": 0.1,
    "snap_interval": 100,
    "feature_timeout": 500,
    "trait_timeout": 500,
    "target_sample": 5
  }
}
```

Any parameter can be provided as a list to enable **parameter sweeps**: the Controller generates the full Cartesian product of all parameter combinations and runs each as a separate experiment condition. This enables systematic exploration of multi-dimensional parameter spaces within a single experiment run.

## Running Experiments

**Single process:**
```bash
python -m model.run config.json
```

**Multiprocessing (local):**
The controller automatically detects available CPUs and dispatches a multiprocessing pool.

**HPC cluster (SLURM):**
The controller detects `SLURM_CPUS_PER_TASK` and uses it to size the process pool. A typical SLURM batch script:

```bash
#!/bin/bash
#SBATCH --cpus-per-task=16
#SBATCH --mem=64G
#SBATCH --time=24:00:00

python -m model.run config.json
```

## Output Structure

Each experiment run creates a timestamped directory:

```
experiment_name_YYYYMMDD_HHMMSS/
├── config.json              # Configuration copy for reproducibility
├── experiment_name.db       # SQLite database (2–40GB depending on scale)
├── experiment_name.txt      # Stdout log for sequential runs
├── experiment_name_1.txt    # Per-network logs for parallel runs
├── experiment_name_2.txt
└── ...
```

The database captures data at multiple levels:
- **World level** — population, utility statistics, phenotype/role counts, interaction rates per timestep
- **Site level** — per-site population dynamics, roleset statistics (viable/occupied/adjacent/occupiable roles)
- **Phenotype level** — per-phenotype population counts by site and timestep
- **Interaction level** — per-interaction counts and utility totals

## Simulation Scale

Typical production runs:
- **Agents:** 150,000–300,000 active agents per world
- **Timesteps:** 25,000–50,000 steps; extended runs to 500,000 steps for long-term dynamics studies
- **Database size:** 2–40GB per experiment depending on collection intervals and run length
- **Parallel worlds:** Multiple networks × multiple iterations per network, dispatched via multiprocessing pool

## Dependencies

```
Mesa==0.9.0
numpy
pandas
matplotlib
seaborn
scipy
networkx
SQLAlchemy
tqdm
```

Install via:
```bash
pip install -r requirements.txt
```

Note: This project pins Mesa 0.9.0 intentionally. All simulation data was generated from this environment, and upgrading dependencies mid-project would compromise reproducibility. Later Mesa versions updated the grid to use sets rather than lists, which solves the deletion bottleneck — sets support O(1) removal where lists require O(n) traversal. However, sets don't support random indexing, so random sampling of agents still requires converting to a sequence first, incurring an O(n) cost every timestep. In a simulation with hundreds of thousands of agents where sampling occurs constantly, that conversion cost is significant. `ListDict` maintains both a dictionary and a list, supporting O(1) removal by ID and O(1) random sampling without conversion.

## Shadow Model

Each primary world runs alongside a **shadow world** — a parallel simulation using the same feature interaction network but with neutral-drift dynamics (no selection pressure). Shadow agents reproduce and mutate but do not interact and face no utility-based mortality. This provides a baseline phenotype distribution against which selection effects in the primary world can be measured, enabling clean separation of drift from selection in the evolutionary dynamics.

## Testing

The project includes a unit test suite covering core components:

```bash
python -m pytest
```

Tests cover `Site`, `Agent`, `Controller`, and `main()` function behavior using `unittest.mock` for isolation of database and filesystem dependencies.
